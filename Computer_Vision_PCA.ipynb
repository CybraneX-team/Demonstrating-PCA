{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-LpkphF49aA"
      },
      "source": [
        "Using Principal Component Analysis (PCA)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7ywRV4QktAt",
        "outputId": "993c02de-6cec-4815-cc30-f426148d60bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n",
            "Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "mbmwP1W_FhMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# Function to load and preprocess image data using ImageDataGenerator\n",
        "def load_image_data(image_dir, target_variable, batch_size=32, img_size=(224, 224)):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "    data_flow = datagen.flow_from_directory(\n",
        "        image_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='sparse'  # For sparse categorical labels\n",
        "    )\n",
        "    images, labels = [], []\n",
        "    for _ in range(len(data_flow)):\n",
        "        img_batch, label_batch = data_flow.next()\n",
        "        images.extend(img_batch)\n",
        "        labels.extend(label_batch)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return images, labels\n",
        "\n",
        "# Function to perform PCA on image data\n",
        "def perform_pca(df):\n",
        "    df_flat = df.reshape(df.shape[0], -1)  # Flatten images\n",
        "    pca = PCA()\n",
        "    pca.fit(df_flat)\n",
        "    explained_variance_ratio = pca.explained_variance_ratio_\n",
        "    return explained_variance_ratio, pca\n",
        "\n",
        "# Function to plot Scree plot\n",
        "def plot_scree(explained_variance_ratio):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.7)\n",
        "    plt.title('Scree Plot')\n",
        "    plt.xlabel('Principal Component')\n",
        "    plt.ylabel('Explained Variance Ratio')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "unfeHL5QFOvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Development and Evaluation"
      ],
      "metadata": {
        "id": "bSGzLTGZFkWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate image classification model\n",
        "def evaluate_image_models(X_train, X_test, y_train, y_test):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(len(np.unique(y_train)), activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    evaluation = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracy = evaluation[1]\n",
        "\n",
        "    results = {\n",
        "        'Training time': training_time,\n",
        "        'Accuracy': accuracy\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage:\n",
        "# Load and preprocess data\n",
        "image_dir = 'path_to_image_directory'  # Directory containing image subfolders\n",
        "target_variable = 'label'\n",
        "X, y = load_image_data(image_dir, target_variable)\n",
        "\n",
        "# PCA analysis\n",
        "explained_variance_ratio, pca = perform_pca(X)\n",
        "plot_scree(explained_variance_ratio)\n",
        "total_variance = explained_variance_ratio.cumsum()[-1]\n",
        "print(f\"\\nTotal Variance Explained by PCA: {total_variance:.4f}\")\n",
        "\n",
        "# Split data and evaluate model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "evaluation_results = evaluate_image_models(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"\\nModel Evaluation Results for Computer Vision:\")\n",
        "for metric_name, value in evaluation_results.items():\n",
        "    print(f\"  {metric_name}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "j7Ez_XSAFWFe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}